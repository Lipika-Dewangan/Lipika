{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd767a77101a446a957551b0ba5829a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1caf427669fd40e7ae52ced43be95a53",
              "IPY_MODEL_87ba9d31e5b1468aa8ce1d1d6e0ba390",
              "IPY_MODEL_41a427a9340f4a8fa19d0b23a3c06774"
            ],
            "layout": "IPY_MODEL_2885b0f02b624f50bf21647130a2a839"
          }
        },
        "1caf427669fd40e7ae52ced43be95a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a65fee1d452744b5af44361aad205c68",
            "placeholder": "​",
            "style": "IPY_MODEL_4fd1f600b1d1452e8152b56c4793a083",
            "value": "Downloading: 100%"
          }
        },
        "87ba9d31e5b1468aa8ce1d1d6e0ba390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a40f92ec90c493aaaed77de5d65d2b1",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef574aa49f48486d820b622790512aed",
            "value": 433
          }
        },
        "41a427a9340f4a8fa19d0b23a3c06774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3138421b35064012a1017dad7334f6a2",
            "placeholder": "​",
            "style": "IPY_MODEL_91c2d05860e9489b8366b30d0f566148",
            "value": " 433/433 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "2885b0f02b624f50bf21647130a2a839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a65fee1d452744b5af44361aad205c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd1f600b1d1452e8152b56c4793a083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a40f92ec90c493aaaed77de5d65d2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef574aa49f48486d820b622790512aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3138421b35064012a1017dad7334f6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c2d05860e9489b8366b30d0f566148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3e701e3a369453ab6e1e89c3ee168d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_710443a8d04942a0b190b1fcfb810b21",
              "IPY_MODEL_36daf5a6430246808d0849373bbdd922",
              "IPY_MODEL_988d0cc36a984059ac01e6682a2e1379"
            ],
            "layout": "IPY_MODEL_010f7105ef9b4f6abab7c95541f40e78"
          }
        },
        "710443a8d04942a0b190b1fcfb810b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de1a7923a694b58b3e3e895e87f3218",
            "placeholder": "​",
            "style": "IPY_MODEL_7f9b08c31e5949958766d34180754436",
            "value": "Downloading: 100%"
          }
        },
        "36daf5a6430246808d0849373bbdd922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e7f15981e804f51972806dee4420caa",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cd49da471c0493689de1447e5949b1e",
            "value": 231508
          }
        },
        "988d0cc36a984059ac01e6682a2e1379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ad292c5a4d49e5bbe9b3991e925466",
            "placeholder": "​",
            "style": "IPY_MODEL_fbfb16aa44fb46e9b5a997e6d633e7cb",
            "value": " 232k/232k [00:00&lt;00:00, 303kB/s]"
          }
        },
        "010f7105ef9b4f6abab7c95541f40e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de1a7923a694b58b3e3e895e87f3218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9b08c31e5949958766d34180754436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e7f15981e804f51972806dee4420caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd49da471c0493689de1447e5949b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22ad292c5a4d49e5bbe9b3991e925466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfb16aa44fb46e9b5a997e6d633e7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55f510ca9294d1b85aa14f33eabff6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e20d53a7730f46db896c069ef2e37139",
              "IPY_MODEL_48311bfecae4439b9ba1d38341c9aec1",
              "IPY_MODEL_ad85236d9e7b4b26a929dcadda3ee9fb"
            ],
            "layout": "IPY_MODEL_516191bf902f4558bc870ff572f5085a"
          }
        },
        "e20d53a7730f46db896c069ef2e37139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5805f138a45c4527bd558b784d053c0d",
            "placeholder": "​",
            "style": "IPY_MODEL_88efae0221494bceac295320d67680d6",
            "value": "Downloading: 100%"
          }
        },
        "48311bfecae4439b9ba1d38341c9aec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa525cf8f444781aa5d47d4bdce6fbb",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f8f0eec06144effa9b251d5434e6f4c",
            "value": 466062
          }
        },
        "ad85236d9e7b4b26a929dcadda3ee9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1d772a323b841b59b76350005147d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_88690f72acd54d819a81ea0ee68d18b0",
            "value": " 466k/466k [00:00&lt;00:00, 852kB/s]"
          }
        },
        "516191bf902f4558bc870ff572f5085a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5805f138a45c4527bd558b784d053c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88efae0221494bceac295320d67680d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfa525cf8f444781aa5d47d4bdce6fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8f0eec06144effa9b251d5434e6f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1d772a323b841b59b76350005147d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88690f72acd54d819a81ea0ee68d18b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d455f9e9054aeba168cef0ed21010d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c18dfc5c2d841ae8acb77182363b136",
              "IPY_MODEL_30c7dfa0b77d48ca87703470e36be3c6",
              "IPY_MODEL_27c3e21df8564569a2704d60ac556223"
            ],
            "layout": "IPY_MODEL_ffd46c57630247ffa487b231260661b7"
          }
        },
        "7c18dfc5c2d841ae8acb77182363b136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4cd8b0932c641a7b448d6095284312f",
            "placeholder": "​",
            "style": "IPY_MODEL_2865834616d44be78147021e337f5446",
            "value": "Downloading: 100%"
          }
        },
        "30c7dfa0b77d48ca87703470e36be3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124fca849f384307ad6ef1cbeaa794fa",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8061e84f170c486f9666b0ee72d242f3",
            "value": 440473133
          }
        },
        "27c3e21df8564569a2704d60ac556223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd07cd0d32ee4131bca906bcd8a897f1",
            "placeholder": "​",
            "style": "IPY_MODEL_04d384dfa3a543b58f65cdfe21d14d5d",
            "value": " 440M/440M [00:07&lt;00:00, 57.7MB/s]"
          }
        },
        "ffd46c57630247ffa487b231260661b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4cd8b0932c641a7b448d6095284312f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2865834616d44be78147021e337f5446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "124fca849f384307ad6ef1cbeaa794fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8061e84f170c486f9666b0ee72d242f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd07cd0d32ee4131bca906bcd8a897f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d384dfa3a543b58f65cdfe21d14d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS6iapf55P0Q",
        "outputId": "22a909c1-00fa-4ee6-bfb5-880eaa36cd07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Span-ASTE'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 194 (delta 60), reused 62 (delta 36), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (194/194), 631.85 KiB | 6.32 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "Note: checking out 'f53ec3c'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at f53ec3c Add command-line scoring instructions in README.md\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Cython==0.29.21\n",
            "  Downloading Cython-0.29.21-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 14.6 MB/s \n",
            "\u001b[?25hCollecting PYEVALB==0.1.3\n",
            "  Downloading PYEVALB-0.1.3-py3-none-any.whl (13 kB)\n",
            "Collecting allennlp-models==1.2.2\n",
            "  Downloading allennlp_models-1.2.2-py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 80.8 MB/s \n",
            "\u001b[?25hCollecting allennlp==1.2.2\n",
            "  Downloading allennlp-1.2.2-py3-none-any.whl (505 kB)\n",
            "\u001b[K     |████████████████████████████████| 505 kB 75.8 MB/s \n",
            "\u001b[?25hCollecting botocore==1.19.46\n",
            "  Downloading botocore-1.19.46-py2.py3-none-any.whl (7.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2 MB 39.0 MB/s \n",
            "\u001b[?25hCollecting fire==0.3.1\n",
            "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting nltk==3.6.6\n",
            "  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 55.7 MB/s \n",
            "\u001b[?25hCollecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 68.9 MB/s \n",
            "\u001b[?25hCollecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 49.5 MB/s \n",
            "\u001b[?25hCollecting pydantic==1.6.2\n",
            "  Downloading pydantic-1.6.2-cp37-cp37m-manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 51.8 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 39.6 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 68.1 MB/s \n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 56.7 MB/s \n",
            "\u001b[?25hCollecting boto3==1.16.46\n",
            "  Downloading boto3-1.16.46-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 67.9 MB/s \n",
            "\u001b[?25hCollecting pytablewriter>=0.10.2\n",
            "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 79.6 MB/s \n",
            "\u001b[?25hCollecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting conllu==4.2.1\n",
            "  Downloading conllu-4.2.1-py2.py3-none-any.whl (14 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.23.0)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 72.8 MB/s \n",
            "\u001b[?25hCollecting spacy<2.4,>=2.1.0\n",
            "  Downloading spacy-2.3.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 44.4 MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 65.3 MB/s \n",
            "\u001b[?25hCollecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.6.4)\n",
            "Collecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (2022.6.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 9)) (2022.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1->-r requirements.txt (line 13)) (7.1.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 66.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (21.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting tabledata<2,>=1.3.0\n",
            "  Downloading tabledata-1.3.0-py3-none-any.whl (11 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
            "Collecting DataProperty<2,>=0.55.0\n",
            "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.2.0\n",
            "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.1.1-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.7/dist-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2.10)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 64.0 MB/s \n",
            "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.9)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.7)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 59.1 MB/s \n",
            "\u001b[?25hCollecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 80.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==1.2.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==1.2.2->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle->allennlp==1.2.2->-r requirements.txt (line 4)) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 14)) (3.0.9)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (9.0.0)\n",
            "Building wheels for collected packages: fire, overrides, jsonnet, word2number, sacremoses\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111023 sha256=14c6ab5971e8e0db6aaf6dac49db53baa981e5975cdaa6868c8561b99f95a416\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/38/e1/8b62337a8ecf5728bdc1017e828f253f7a9cf25db999861bec\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=538389e0192f002487fc35dd4fdee42d19387726bddaaea5a86cae8950fd28db\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=3997159 sha256=5ccbece4eba1b58392e6b6e657d7f01dcd0e09b9f06f81c44f25f65ba3422b51\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/6b/48/a168ed5f8d01c50268605eff341c29126286763607bf707e3b\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=e8de76e49c2bf280b8d9d4e8d6bcb63ad0173657f7aca60614c457c57bdd9355\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d25464e31f482b81a00124a38f0c8c8da869017254abcbe1f202fe40c7151e22\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built fire overrides jsonnet word2number sacremoses\n",
            "Installing collected packages: mbstrdecoder, urllib3, typepy, numpy, jmespath, srsly, plac, catalogue, botocore, tokenizers, thinc, sentencepiece, sacremoses, s3transfer, filelock, DataProperty, dataclasses, transformers, torch, tensorboardX, tcolorpy, tabledata, spacy, scikit-learn, pathvalidate, overrides, nltk, jsonpickle, jsonnet, boto3, word2number, pytablewriter, py-rouge, ftfy, conllu, allennlp, torchvision, PYEVALB, pydantic, pandas, fire, Cython, allennlp-models\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.5\n",
            "    Uninstalling srsly-2.4.5:\n",
            "      Successfully uninstalled srsly-2.4.5\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.5\n",
            "    Uninstalling thinc-8.1.5:\n",
            "      Successfully uninstalled thinc-8.1.5\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.3\n",
            "    Uninstalling spacy-3.4.3:\n",
            "      Successfully uninstalled spacy-3.4.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.2\n",
            "    Uninstalling pydantic-1.10.2:\n",
            "      Successfully uninstalled pydantic-1.10.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.32\n",
            "    Uninstalling Cython-0.29.32:\n",
            "      Successfully uninstalled Cython-0.29.32\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.8 which is incompatible.\n",
            "confection 0.0.3 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.6.2 which is incompatible.\n",
            "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.21 DataProperty-0.55.0 PYEVALB-0.1.3 allennlp-1.2.2 allennlp-models-1.2.2 boto3-1.16.46 botocore-1.19.46 catalogue-1.0.2 conllu-4.2.1 dataclasses-0.6 filelock-3.0.12 fire-0.3.1 ftfy-6.1.1 jmespath-0.10.0 jsonnet-0.19.1 jsonpickle-2.2.0 mbstrdecoder-1.1.1 nltk-3.6.6 numpy-1.21.5 overrides-3.1.0 pandas-1.1.5 pathvalidate-2.5.2 plac-1.1.3 py-rouge-1.1 pydantic-1.6.2 pytablewriter-0.64.2 s3transfer-0.3.7 sacremoses-0.0.53 scikit-learn-0.22.2.post1 sentencepiece-0.1.97 spacy-2.3.8 srsly-1.0.6 tabledata-1.3.0 tcolorpy-0.1.2 tensorboardX-2.5.1 thinc-7.4.6 tokenizers-0.9.2 torch-1.7.0 torchvision-0.8.1 transformers-3.4.0 typepy-1.3.0 urllib3-1.25.11 word2number-1.1\n",
            "Found existing installation: dataclasses 0.6\n",
            "Uninstalling dataclasses-0.6:\n",
            "  Successfully uninstalled dataclasses-0.6\n",
            "Archive:  data.zip\n",
            "   creating: aste/data/\n",
            "   creating: aste/data/triplet_data/\n",
            "   creating: aste/data/triplet_data/14lap/\n",
            "  inflating: aste/data/triplet_data/14lap/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/test.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/train.txt  \n",
            "   creating: aste/data/triplet_data/14res/\n",
            "  inflating: aste/data/triplet_data/14res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14res/test.txt  \n",
            "  inflating: aste/data/triplet_data/14res/train.txt  \n",
            "   creating: aste/data/triplet_data/15res/\n",
            "  inflating: aste/data/triplet_data/15res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/15res/test.txt  \n",
            "  inflating: aste/data/triplet_data/15res/train.txt  \n",
            "   creating: aste/data/triplet_data/16res/\n",
            "  inflating: aste/data/triplet_data/16res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/16res/test.txt  \n",
            "  inflating: aste/data/triplet_data/16res/train.txt  \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
        "!cd Span-ASTE && git checkout f53ec3c\n",
        "!cp -a Span-ASTE/* .\n",
        "!echo boto3==1.16.46 >> requirements.txt\n",
        "!bash setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Exploration\n",
        "data_name = \"14lap\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]"
      ],
      "metadata": {
        "id": "wcn-U8qy5-dX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from data_utils import Data\n",
        "\n",
        "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "data = Data.load_from_full_path(path)\n",
        "\n",
        "for s in data.sentences[:3]:\n",
        "    print(\"tokens:\", s.tokens)\n",
        "    for t in s.triples:\n",
        "        print(\"target:\", (t.t_start, t.t_end))\n",
        "        print(\"opinion:\", (t.o_start, t.o_end))\n",
        "        print(\"label:\", t.label)\n",
        "    print()"
      ],
      "metadata": {
        "id": "UEpB0l5H7pBg",
        "outputId": "a638e549-77a3-4cd0-9880-d20166f222c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\n",
            "target: (16, 17)\n",
            "opinion: (15, 15)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['it', 'is', 'of', 'high', 'quality', ',', 'has', 'a', 'killer', 'GUI', ',', 'is', 'extremely', 'stable', ',', 'is', 'highly', 'expandable', ',', 'is', 'bundled', 'with', 'lots', 'of', 'very', 'good', 'applications', ',', 'is', 'easy', 'to', 'use', ',', 'and', 'is', 'absolutely', 'gorgeous', '.']\n",
            "target: (4, 4)\n",
            "opinion: (3, 3)\n",
            "label: LabelEnum.positive\n",
            "target: (9, 9)\n",
            "opinion: (8, 8)\n",
            "label: LabelEnum.positive\n",
            "target: (26, 26)\n",
            "opinion: (25, 25)\n",
            "label: LabelEnum.positive\n",
            "target: (31, 31)\n",
            "opinion: (29, 29)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['Easy', 'to', 'start', 'up', 'and', 'does', 'not', 'overheat', 'as', 'much', 'as', 'other', 'laptops', '.']\n",
            "target: (2, 3)\n",
            "opinion: (0, 0)\n",
            "label: LabelEnum.positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained SpanModel weights\n",
        "from pathlib import Path\n",
        "template = \"https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/{}.tar\"\n",
        "url = template.format(data_name)\n",
        "model_tar = Path(url).name\n",
        "model_dir = Path(url).stem\n",
        "\n",
        "!wget -nc $url\n",
        "!tar -xf $model_tar"
      ],
      "metadata": {
        "id": "_P1vNwO28dMe",
        "outputId": "d6a28977-a996-472c-d285-46ed0ca46e93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-30 09:50:50--  https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/14lap.tar\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/70bb2013-2773-44c0-b0d9-8a2ec8e38515?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221130%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221130T095050Z&X-Amz-Expires=300&X-Amz-Signature=a355a1624e48d87a0e36ea0b598cf4d2c00d2800f710063ca49c948cecf48738&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3D14lap.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-30 09:50:50--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/70bb2013-2773-44c0-b0d9-8a2ec8e38515?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221130%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221130T095050Z&X-Amz-Expires=300&X-Amz-Signature=a355a1624e48d87a0e36ea0b598cf4d2c00d2800f710063ca49c948cecf48738&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3D14lap.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409068544 (390M) [application/octet-stream]\n",
            "Saving to: ‘14lap.tar’\n",
            "\n",
            "14lap.tar           100%[===================>] 390.12M  6.77MB/s    in 58s     \n",
            "\n",
            "2022-11-30 09:51:50 (6.67 MB/s) - ‘14lap.tar’ saved [409068544/409068544]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pretrained SpanModel weights for prediction\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from pathlib import Path\n",
        "from data_utils import Data, Sentence, SplitEnum\n",
        "from wrapper import SpanModel\n",
        "\n",
        "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
        "    path_in = \"temp_in.txt\"\n",
        "    path_out = \"temp_out.txt\"\n",
        "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
        "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
        "    data.save_to_path(path_in)\n",
        "    model.predict(path_in, path_out)\n",
        "    data = Data.load_from_full_path(path_out)\n",
        "    return data.sentences[0]\n",
        "\n",
        "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
        "model = SpanModel(save_dir=model_dir, random_seed=0)\n",
        "sent = predict_sentence(text, model)\n",
        "\n",
        "for t in sent.triples:\n",
        "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
        "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
        "    print()\n",
        "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
      ],
      "metadata": {
        "id": "y2xcJYX_84IX",
        "outputId": "5b7ea0ca-089d-40be-f84b-a58d6282884c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "dd767a77101a446a957551b0ba5829a7",
            "1caf427669fd40e7ae52ced43be95a53",
            "87ba9d31e5b1468aa8ce1d1d6e0ba390",
            "41a427a9340f4a8fa19d0b23a3c06774",
            "2885b0f02b624f50bf21647130a2a839",
            "a65fee1d452744b5af44361aad205c68",
            "4fd1f600b1d1452e8152b56c4793a083",
            "8a40f92ec90c493aaaed77de5d65d2b1",
            "ef574aa49f48486d820b622790512aed",
            "3138421b35064012a1017dad7334f6a2",
            "91c2d05860e9489b8366b30d0f566148",
            "a3e701e3a369453ab6e1e89c3ee168d3",
            "710443a8d04942a0b190b1fcfb810b21",
            "36daf5a6430246808d0849373bbdd922",
            "988d0cc36a984059ac01e6682a2e1379",
            "010f7105ef9b4f6abab7c95541f40e78",
            "6de1a7923a694b58b3e3e895e87f3218",
            "7f9b08c31e5949958766d34180754436",
            "4e7f15981e804f51972806dee4420caa",
            "7cd49da471c0493689de1447e5949b1e",
            "22ad292c5a4d49e5bbe9b3991e925466",
            "fbfb16aa44fb46e9b5a997e6d633e7cb",
            "d55f510ca9294d1b85aa14f33eabff6b",
            "e20d53a7730f46db896c069ef2e37139",
            "48311bfecae4439b9ba1d38341c9aec1",
            "ad85236d9e7b4b26a929dcadda3ee9fb",
            "516191bf902f4558bc870ff572f5085a",
            "5805f138a45c4527bd558b784d053c0d",
            "88efae0221494bceac295320d67680d6",
            "cfa525cf8f444781aa5d47d4bdce6fbb",
            "7f8f0eec06144effa9b251d5434e6f4c",
            "e1d772a323b841b59b76350005147d3d",
            "88690f72acd54d819a81ea0ee68d18b0",
            "21d455f9e9054aeba168cef0ed21010d",
            "7c18dfc5c2d841ae8acb77182363b136",
            "30c7dfa0b77d48ca87703470e36be3c6",
            "27c3e21df8564569a2704d60ac556223",
            "ffd46c57630247ffa487b231260661b7",
            "c4cd8b0932c641a7b448d6095284312f",
            "2865834616d44be78147021e337f5446",
            "124fca849f384307ad6ef1cbeaa794fa",
            "8061e84f170c486f9666b0ee72d242f3",
            "cd07cd0d32ee4131bca906bcd8a897f1",
            "04d384dfa3a543b58f65cdfe21d14d5d"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd767a77101a446a957551b0ba5829a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3e701e3a369453ab6e1e89c3ee168d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d55f510ca9294d1b85aa14f33eabff6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "################################################################################\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21d455f9e9054aeba168cef0ed21010d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f0d489acef0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__relation_labels, Size: 3 || None__ner_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 1it [00:00, 390.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'target': 'Windows 8', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'touchscreen functions', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'Windows 8', 'opinion': 'new', 'sentiment': <LabelEnum.neutral: 'NEU'>}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SpanModel from scratch\n",
        "random_seed = 4\n",
        "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
        "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
        "\n",
        "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
        "model.fit(path_train, path_dev)"
      ],
      "metadata": {
        "id": "OnXL8M729iPO",
        "outputId": "e0adbf58-54b6-4f57-f523-b6614aa2fd73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weights_dir': PosixPath('outputs/14lap/seed_4/weights')}\n",
            "2022-11-30 09:55:12,340 - INFO - allennlp.common.params - random_seed = 4\n",
            "2022-11-30 09:55:12,342 - INFO - allennlp.common.params - numpy_seed = 4\n",
            "2022-11-30 09:55:12,343 - INFO - allennlp.common.params - pytorch_seed = 4\n",
            "2022-11-30 09:55:12,345 - INFO - allennlp.common.checks - Pytorch version: 1.7.0\n",
            "2022-11-30 09:55:12,346 - INFO - allennlp.common.params - type = default\n",
            "2022-11-30 09:55:12,353 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
            "2022-11-30 09:55:12,355 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-11-30 09:55:12,357 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-11-30 09:55:12,360 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-11-30 09:55:12,361 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-11-30 09:55:12,363 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-11-30 09:55:12,367 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
            "2022-11-30 09:55:12,370 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 09:55:12,371 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
            "2022-11-30 09:55:12,374 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
            "2022-11-30 09:55:12,375 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
            "2022-11-30 09:55:12,378 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
            "2022-11-30 09:55:12,380 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
            "################################################################################\n",
            "2022-11-30 09:55:12,382 - INFO - allennlp.common.params - train_data_path = /content/outputs/14lap/seed_4/temp_data/train.json\n",
            "2022-11-30 09:55:12,384 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f0d4991a350>\n",
            "2022-11-30 09:55:12,386 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
            "2022-11-30 09:55:12,388 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2022-11-30 09:55:12,393 - INFO - allennlp.common.params - validation_data_path = /content/outputs/14lap/seed_4/temp_data/dev.json\n",
            "2022-11-30 09:55:12,395 - INFO - allennlp.common.params - validation_data_loader = None\n",
            "2022-11-30 09:55:12,398 - INFO - allennlp.common.params - test_data_path = /content/outputs/14lap/seed_4/temp_data/dev.json\n",
            "2022-11-30 09:55:12,400 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2022-11-30 09:55:12,402 - INFO - allennlp.common.params - batch_weight_key = \n",
            "2022-11-30 09:55:12,404 - INFO - allennlp.training.util - Reading training data from /content/outputs/14lap/seed_4/temp_data/train.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 906it [00:01, 740.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:55:13,637 - INFO - allennlp.training.util - Reading validation data from /content/outputs/14lap/seed_4/temp_data/dev.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "reading instances: 219it [00:00, 1169.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:55:13,833 - INFO - allennlp.training.util - Reading test data from /content/outputs/14lap/seed_4/temp_data/dev.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 219it [00:00, 467.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:55:14,309 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-11-30 09:55:14,311 - INFO - allennlp.common.params - min_count = None\n",
            "2022-11-30 09:55:14,316 - INFO - allennlp.common.params - max_vocab_size = None\n",
            "2022-11-30 09:55:14,317 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
            "2022-11-30 09:55:14,320 - INFO - allennlp.common.params - pretrained_files = None\n",
            "2022-11-30 09:55:14,321 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
            "2022-11-30 09:55:14,323 - INFO - allennlp.common.params - tokens_to_add = None\n",
            "2022-11-30 09:55:14,329 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
            "2022-11-30 09:55:14,330 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
            "2022-11-30 09:55:14,332 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
            "2022-11-30 09:55:14,335 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "building vocab: 1344it [00:00, 15429.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:55:14,429 - INFO - allennlp.common.params - model.type = span_model\n",
            "2022-11-30 09:55:14,433 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-11-30 09:55:14,434 - INFO - allennlp.common.params - model.embedder.type = basic\n",
            "2022-11-30 09:55:14,438 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 09:55:14,440 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
            "2022-11-30 09:55:14,444 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
            "2022-11-30 09:55:14,445 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
            "2022-11-30 09:55:14,446 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
            "2022-11-30 09:55:14,448 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
            "2022-11-30 09:55:14,449 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
            "2022-11-30 09:55:14,453 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:55:14,543 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
            "2022-11-30 09:55:14,544 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
            "2022-11-30 09:55:14,547 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
            "2022-11-30 09:55:14,551 - INFO - allennlp.common.params - model.feature_size = 20\n",
            "2022-11-30 09:55:14,554 - INFO - allennlp.common.params - model.max_span_width = 8\n",
            "2022-11-30 09:55:14,556 - INFO - allennlp.common.params - model.target_task = relation\n",
            "2022-11-30 09:55:14,559 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
            "2022-11-30 09:55:14,563 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
            "2022-11-30 09:55:14,565 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
            "2022-11-30 09:55:14,567 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
            "2022-11-30 09:55:14,569 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
            "2022-11-30 09:55:14,571 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
            "2022-11-30 09:55:14,573 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
            "2022-11-30 09:55:14,574 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
            "2022-11-30 09:55:14,580 - INFO - allennlp.common.params - model.display_metrics = None\n",
            "2022-11-30 09:55:14,582 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
            "2022-11-30 09:55:14,584 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "2022-11-30 09:55:14,589 - INFO - allennlp.common.params - ner.regularizer = None\n",
            "2022-11-30 09:55:14,590 - INFO - allennlp.common.params - ner.name = ner_labels\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "2022-11-30 09:55:14,598 - INFO - allennlp.common.params - relation.regularizer = None\n",
            "2022-11-30 09:55:14,601 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
            "2022-11-30 09:55:14,602 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
            "2022-11-30 09:55:14,605 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
            "2022-11-30 09:55:14,606 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
            "2022-11-30 09:55:14,609 - INFO - allennlp.common.params - relation.use_pruning = True\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f0cb28ffef0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "2022-11-30 09:55:14,625 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 09:55:14,626 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,633 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,635 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,638 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-11-30 09:55:14,639 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 09:55:14,641 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 09:55:14,643 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 09:55:14,647 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 09:55:14,648 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 09:55:14,651 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,654 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,663 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,665 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
            "2022-11-30 09:55:14,668 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-11-30 09:55:14,669 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 09:55:14,671 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 09:55:14,673 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 09:55:14,675 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 09:55:14,677 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 09:55:14,679 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
            "2022-11-30 09:55:14,684 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 09:55:14,686 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-11-30 09:55:14,687 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-11-30 09:55:14,688 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-11-30 09:55:14,690 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-11-30 09:55:14,694 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-11-30 09:55:14,695 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,698 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,701 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,704 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,705 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-11-30 09:55:14,707 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-11-30 09:55:14,710 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-11-30 09:55:14,712 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-11-30 09:55:14,717 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-11-30 09:55:14,719 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-11-30 09:55:14,721 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,723 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,726 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,728 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,729 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-11-30 09:55:14,733 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-11-30 09:55:14,735 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,736 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,737 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,739 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,743 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-11-30 09:55:14,745 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-11-30 09:55:14,747 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-11-30 09:55:14,749 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-11-30 09:55:14,753 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-11-30 09:55:14,756 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-11-30 09:55:14,758 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,759 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,761 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,763 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,765 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-11-30 09:55:14,768 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-11-30 09:55:14,776 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,777 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,779 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,783 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,784 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-11-30 09:55:14,786 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-11-30 09:55:14,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-11-30 09:55:14,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-11-30 09:55:14,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-11-30 09:55:14,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-11-30 09:55:14,799 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,801 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,804 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,806 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,812 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-11-30 09:55:14,813 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-11-30 09:55:14,816 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,817 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,818 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,820 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,824 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-11-30 09:55:14,825 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-11-30 09:55:14,826 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-11-30 09:55:14,828 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-11-30 09:55:14,831 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-11-30 09:55:14,832 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-11-30 09:55:14,834 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,839 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,842 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,843 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,844 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-11-30 09:55:14,846 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-11-30 09:55:14,847 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,856 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-11-30 09:55:14,857 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-11-30 09:55:14,859 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-11-30 09:55:14,867 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-11-30 09:55:14,869 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-11-30 09:55:14,873 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-11-30 09:55:14,876 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,878 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,880 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,882 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,884 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-11-30 09:55:14,888 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-11-30 09:55:14,890 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,892 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,894 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,897 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,899 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-11-30 09:55:14,902 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-11-30 09:55:14,903 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-11-30 09:55:14,905 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-11-30 09:55:14,907 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-11-30 09:55:14,910 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-11-30 09:55:14,912 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,914 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-11-30 09:55:14,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-11-30 09:55:14,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,926 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,928 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,929 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,937 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-11-30 09:55:14,939 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-11-30 09:55:14,941 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-11-30 09:55:14,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-11-30 09:55:14,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-11-30 09:55:14,949 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-11-30 09:55:14,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,958 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-11-30 09:55:14,961 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-11-30 09:55:14,963 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,964 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,968 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-11-30 09:55:14,970 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-11-30 09:55:14,971 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-11-30 09:55:14,974 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-11-30 09:55:14,976 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-11-30 09:55:14,977 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-11-30 09:55:14,981 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-11-30 09:55:14,982 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-11-30 09:55:14,984 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-11-30 09:55:14,989 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-11-30 09:55:14,991 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-11-30 09:55:14,994 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-11-30 09:55:14,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-11-30 09:55:14,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-11-30 09:55:15,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,007 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,009 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-11-30 09:55:15,012 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-11-30 09:55:15,014 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-11-30 09:55:15,015 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-11-30 09:55:15,019 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-11-30 09:55:15,020 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-11-30 09:55:15,022 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,023 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,028 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,030 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,032 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-11-30 09:55:15,036 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-11-30 09:55:15,037 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,042 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,044 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,048 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,049 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-11-30 09:55:15,052 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-11-30 09:55:15,057 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-11-30 09:55:15,059 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-11-30 09:55:15,062 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-11-30 09:55:15,065 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-11-30 09:55:15,070 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,080 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-11-30 09:55:15,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-11-30 09:55:15,084 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,090 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,092 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-11-30 09:55:15,093 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-11-30 09:55:15,094 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-11-30 09:55:15,097 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-11-30 09:55:15,099 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-11-30 09:55:15,106 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-11-30 09:55:15,108 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,111 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,112 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,114 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,116 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-11-30 09:55:15,118 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-11-30 09:55:15,124 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,125 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,130 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,131 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,132 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-11-30 09:55:15,135 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-11-30 09:55:15,136 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-11-30 09:55:15,138 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-11-30 09:55:15,142 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-11-30 09:55:15,144 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-11-30 09:55:15,146 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,148 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,150 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,152 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,154 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-11-30 09:55:15,159 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-11-30 09:55:15,160 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-11-30 09:55:15,165 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-11-30 09:55:15,167 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 09:55:15,169 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-11-30 09:55:15,172 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 09:55:15,175 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-11-30 09:55:15,176 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 09:55:15,178 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-11-30 09:55:15,186 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 09:55:15,187 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-11-30 09:55:15,190 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 09:55:15,193 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-11-30 09:55:15,196 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 09:55:15,198 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-11-30 09:55:15,200 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
            "2022-11-30 09:55:15,205 - INFO - filelock - Lock 139692515430544 acquired on outputs/14lap/seed_4/weights/vocabulary/.lock\n",
            "2022-11-30 09:55:15,207 - INFO - filelock - Lock 139692515430544 released on outputs/14lap/seed_4/weights/vocabulary/.lock\n",
            "2022-11-30 09:55:15,209 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-11-30 09:55:15,212 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-11-30 09:55:15,213 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-11-30 09:55:15,216 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-11-30 09:55:15,217 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-11-30 09:55:15,219 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-11-30 09:55:15,222 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-11-30 09:55:15,224 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-11-30 09:55:15,226 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-11-30 09:55:15,227 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-11-30 09:55:15,228 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-11-30 09:55:15,230 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-11-30 09:55:15,234 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-11-30 09:55:15,235 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-11-30 09:55:15,239 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-11-30 09:55:15,240 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-11-30 09:55:15,242 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-11-30 09:55:15,244 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-11-30 09:55:15,247 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-11-30 09:55:15,248 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-11-30 09:55:15,250 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-11-30 09:55:15,254 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-11-30 09:55:15,255 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-11-30 09:55:15,257 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-11-30 09:55:15,261 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-11-30 09:55:15,263 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-11-30 09:55:15,265 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-11-30 09:55:15,269 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-11-30 09:55:15,270 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-11-30 09:55:15,272 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-11-30 09:55:15,273 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-11-30 09:55:15,275 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-11-30 09:55:15,277 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-11-30 09:55:15,283 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-11-30 09:55:15,284 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-11-30 09:55:15,287 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-11-30 09:55:15,289 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-11-30 09:55:15,290 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-11-30 09:55:15,295 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-11-30 09:55:15,297 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-11-30 09:55:15,299 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-11-30 09:55:15,301 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-11-30 09:55:15,307 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
            "2022-11-30 09:55:15,309 - INFO - allennlp.common.params - trainer.patience = None\n",
            "2022-11-30 09:55:15,313 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
            "2022-11-30 09:55:15,316 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
            "2022-11-30 09:55:15,317 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2022-11-30 09:55:15,320 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
            "2022-11-30 09:55:15,321 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2022-11-30 09:55:15,323 - INFO - allennlp.common.params - trainer.distributed = False\n",
            "2022-11-30 09:55:15,325 - INFO - allennlp.common.params - trainer.world_size = 1\n",
            "2022-11-30 09:55:15,327 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
            "2022-11-30 09:55:15,328 - INFO - allennlp.common.params - trainer.use_amp = False\n",
            "2022-11-30 09:55:15,330 - INFO - allennlp.common.params - trainer.no_grad = None\n",
            "2022-11-30 09:55:15,332 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2022-11-30 09:55:15,333 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f0d498ee850>\n",
            "2022-11-30 09:55:15,342 - INFO - allennlp.common.params - trainer.moving_average = None\n",
            "2022-11-30 09:55:15,343 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
            "2022-11-30 09:55:15,346 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
            "2022-11-30 09:55:15,348 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
            "2022-11-30 09:55:15,349 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
            "2022-11-30 09:55:15,504 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
            "2022-11-30 09:55:15,507 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
            "2022-11-30 09:55:15,508 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
            "2022-11-30 09:55:15,511 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
            "2022-11-30 09:55:15,513 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
            "2022-11-30 09:55:15,517 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
            "2022-11-30 09:55:15,520 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
            "2022-11-30 09:55:15,523 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
            "2022-11-30 09:55:15,525 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
            "2022-11-30 09:55:15,527 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_endpoint_span_extractor._span_width_embedding.weight', '_ner._ner_scorers.None__ner_labels.1._module.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_scorers.None__relation_labels.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_relation.d_embedder.embedder.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation._relation_scorers.None__relation_labels.weight'], {}\n",
            "2022-11-30 09:55:15,528 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
            "2022-11-30 09:55:15,534 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110249737\n",
            "2022-11-30 09:55:15,538 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
            "2022-11-30 09:55:15,542 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
            "2022-11-30 09:55:15,544 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
            "2022-11-30 09:55:15,547 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-11-30 09:55:15,550 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-11-30 09:55:15,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-11-30 09:55:15,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-11-30 09:55:15,557 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-11-30 09:55:15,558 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-11-30 09:55:15,561 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-11-30 09:55:15,563 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-11-30 09:55:15,564 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-11-30 09:55:15,568 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-11-30 09:55:15,569 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-11-30 09:55:15,573 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,579 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,586 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,588 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-11-30 09:55:15,591 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-11-30 09:55:15,593 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,597 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-11-30 09:55:15,600 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-11-30 09:55:15,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-11-30 09:55:15,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-11-30 09:55:15,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-11-30 09:55:15,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-11-30 09:55:15,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,624 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,627 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,630 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-11-30 09:55:15,631 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-11-30 09:55:15,632 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,633 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,635 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-11-30 09:55:15,637 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-11-30 09:55:15,642 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-11-30 09:55:15,644 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-11-30 09:55:15,648 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-11-30 09:55:15,649 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-11-30 09:55:15,651 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,656 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,657 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,661 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,664 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,668 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,670 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-11-30 09:55:15,676 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-11-30 09:55:15,678 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,680 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,683 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-11-30 09:55:15,684 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-11-30 09:55:15,686 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-11-30 09:55:15,687 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-11-30 09:55:15,690 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-11-30 09:55:15,692 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-11-30 09:55:15,698 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,700 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,702 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,703 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,705 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,707 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,709 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-11-30 09:55:15,711 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-11-30 09:55:15,717 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,723 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,724 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-11-30 09:55:15,726 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-11-30 09:55:15,729 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-11-30 09:55:15,733 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-11-30 09:55:15,735 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-11-30 09:55:15,737 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-11-30 09:55:15,739 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,740 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,742 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,746 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,748 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,752 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,755 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-11-30 09:55:15,758 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-11-30 09:55:15,759 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,761 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,765 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-11-30 09:55:15,766 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-11-30 09:55:15,768 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-11-30 09:55:15,772 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-11-30 09:55:15,773 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-11-30 09:55:15,774 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-11-30 09:55:15,776 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,778 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,780 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,786 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,788 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,793 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,794 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-11-30 09:55:15,796 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-11-30 09:55:15,797 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,800 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,801 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-11-30 09:55:15,803 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-11-30 09:55:15,805 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-11-30 09:55:15,807 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-11-30 09:55:15,817 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-11-30 09:55:15,818 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-11-30 09:55:15,820 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,822 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,828 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,829 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,832 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,837 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,838 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-11-30 09:55:15,839 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-11-30 09:55:15,841 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,845 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,847 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-11-30 09:55:15,849 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-11-30 09:55:15,850 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-11-30 09:55:15,852 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-11-30 09:55:15,857 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-11-30 09:55:15,860 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-11-30 09:55:15,861 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,865 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,867 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,868 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,872 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,873 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,877 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-11-30 09:55:15,880 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-11-30 09:55:15,881 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,883 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,887 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-11-30 09:55:15,890 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-11-30 09:55:15,893 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-11-30 09:55:15,895 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-11-30 09:55:15,897 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-11-30 09:55:15,901 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-11-30 09:55:15,904 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,906 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,909 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,911 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,913 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,915 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,917 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-11-30 09:55:15,918 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-11-30 09:55:15,920 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,922 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,927 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-11-30 09:55:15,929 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-11-30 09:55:15,932 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-11-30 09:55:15,934 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-11-30 09:55:15,937 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-11-30 09:55:15,938 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-11-30 09:55:15,941 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,944 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,947 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,949 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,952 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,954 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,955 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-11-30 09:55:15,960 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-11-30 09:55:15,961 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,964 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,967 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-11-30 09:55:15,968 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-11-30 09:55:15,971 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-11-30 09:55:15,973 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-11-30 09:55:15,975 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-11-30 09:55:15,979 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-11-30 09:55:15,982 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-11-30 09:55:15,984 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-11-30 09:55:15,988 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:15,989 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:15,991 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-11-30 09:55:15,992 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-11-30 09:55:15,998 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-11-30 09:55:16,000 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-11-30 09:55:16,001 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-11-30 09:55:16,003 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-11-30 09:55:16,009 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-11-30 09:55:16,010 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-11-30 09:55:16,012 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-11-30 09:55:16,015 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-11-30 09:55:16,017 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-11-30 09:55:16,019 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-11-30 09:55:16,021 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-11-30 09:55:16,023 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-11-30 09:55:16,024 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-11-30 09:55:16,026 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-11-30 09:55:16,028 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-11-30 09:55:16,030 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-11-30 09:55:16,032 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-11-30 09:55:16,034 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-11-30 09:55:16,036 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-11-30 09:55:16,038 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-11-30 09:55:16,048 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-11-30 09:55:16,052 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-11-30 09:55:16,054 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-11-30 09:55:16,056 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 09:55:16,058 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-11-30 09:55:16,064 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 09:55:16,066 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-11-30 09:55:16,068 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 09:55:16,071 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
            "2022-11-30 09:55:16,074 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-11-30 09:55:16,077 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 09:55:16,080 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-11-30 09:55:16,082 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 09:55:16,083 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-11-30 09:55:16,085 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 09:55:16,088 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
            "2022-11-30 09:55:16,091 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
            "2022-11-30 09:55:16,095 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
            "2022-11-30 09:55:16,097 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
            "2022-11-30 09:55:16,099 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
            "2022-11-30 09:55:16,100 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
            "2022-11-30 09:55:16,104 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
            "2022-11-30 09:55:16,106 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
            "2022-11-30 09:55:16,108 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
            "2022-11-30 09:55:16,109 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
            "2022-11-30 09:55:16,111 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
            "2022-11-30 09:55:16,112 - INFO - allennlp.common.params - summary_interval = 100\n",
            "2022-11-30 09:55:16,114 - INFO - allennlp.common.params - histogram_interval = None\n",
            "2022-11-30 09:55:16,116 - INFO - allennlp.common.params - batch_size_interval = None\n",
            "2022-11-30 09:55:16,118 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
            "2022-11-30 09:55:16,126 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
            "2022-11-30 09:55:16,127 - INFO - allennlp.common.params - get_batch_num_total = None\n",
            "2022-11-30 09:55:16,133 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "2022-11-30 09:55:16,136 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2022-11-30 09:55:16,138 - INFO - allennlp.training.trainer - Epoch 0/9\n",
            "2022-11-30 09:55:16,141 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 09:55:16,144 - INFO - allennlp.training.trainer - GPU 0 memory usage: 844M\n",
            "2022-11-30 09:55:16,148 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/906 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:55:16,304 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.0648, MEAN__relation_recall: 0.0479, MEAN__relation_f1: 0.0551, batch_loss: 5.6090, loss: 20.0737 ||: 100%|##########| 906/906 [01:27<00:00, 10.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:56:44,808 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.5678, MEAN__relation_recall: 0.1942, MEAN__relation_f1: 0.2894, batch_loss: 3.0805, loss: 9.3331 ||: 100%|##########| 219/219 [00:05<00:00, 41.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:56:50,157 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 09:56:50,160 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.055  |     0.289\n",
            "2022-11-30 09:56:50,163 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.065  |     0.568\n",
            "2022-11-30 09:56:50,168 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.048  |     0.194\n",
            "2022-11-30 09:56:50,171 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.330  |     0.721\n",
            "2022-11-30 09:56:50,175 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.319  |     0.744\n",
            "2022-11-30 09:56:50,177 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.341  |     0.698\n",
            "2022-11-30 09:56:50,179 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.330  |     0.721\n",
            "2022-11-30 09:56:50,183 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.319  |     0.744\n",
            "2022-11-30 09:56:50,186 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.341  |     0.698\n",
            "2022-11-30 09:56:50,188 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.055  |     0.289\n",
            "2022-11-30 09:56:50,191 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.065  |     0.568\n",
            "2022-11-30 09:56:50,195 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.048  |     0.194\n",
            "2022-11-30 09:56:50,198 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |   843.606  |       N/A\n",
            "2022-11-30 09:56:50,201 - INFO - allennlp.training.tensorboard_writer - loss                      |    20.074  |     9.333\n",
            "2022-11-30 09:56:50,209 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4133.449  |       N/A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:56:52,718 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 09:56:54,490 - INFO - allennlp.training.trainer - Epoch duration: 0:01:38.352594\n",
            "2022-11-30 09:56:54,742 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:14:47\n",
            "2022-11-30 09:56:54,744 - INFO - allennlp.training.trainer - Epoch 1/9\n",
            "2022-11-30 09:56:54,747 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 09:56:54,749 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 09:56:54,753 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.4840, MEAN__relation_recall: 0.3110, MEAN__relation_f1: 0.3786, batch_loss: 10.6017, loss: 9.7407 ||: 100%|##########| 906/906 [01:25<00:00, 10.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:58:21,213 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.8000, MEAN__relation_recall: 0.1739, MEAN__relation_f1: 0.2857, batch_loss: 10.1005, loss: 8.9969 ||: 100%|##########| 219/219 [00:05<00:00, 43.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:58:26,267 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 09:58:26,268 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.379  |     0.286\n",
            "2022-11-30 09:58:26,273 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.484  |     0.800\n",
            "2022-11-30 09:58:26,275 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.311  |     0.174\n",
            "2022-11-30 09:58:26,279 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.748  |     0.770\n",
            "2022-11-30 09:58:26,282 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.782  |     0.785\n",
            "2022-11-30 09:58:26,285 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.717  |     0.755\n",
            "2022-11-30 09:58:26,289 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.748  |     0.770\n",
            "2022-11-30 09:58:26,291 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.782  |     0.785\n",
            "2022-11-30 09:58:26,294 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.717  |     0.755\n",
            "2022-11-30 09:58:26,296 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.379  |     0.286\n",
            "2022-11-30 09:58:26,301 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.484  |     0.800\n",
            "2022-11-30 09:58:26,304 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.311  |     0.174\n",
            "2022-11-30 09:58:26,308 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 09:58:26,309 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.741  |     8.997\n",
            "2022-11-30 09:58:26,314 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 09:58:28,815 - INFO - allennlp.training.trainer - Epoch duration: 0:01:34.070819\n",
            "2022-11-30 09:58:28,817 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:12:50\n",
            "2022-11-30 09:58:28,818 - INFO - allennlp.training.trainer - Epoch 2/9\n",
            "2022-11-30 09:58:28,823 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 09:58:28,826 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 09:58:28,829 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6140, MEAN__relation_recall: 0.5274, MEAN__relation_f1: 0.5674, batch_loss: 0.2614, loss: 7.3868 ||: 100%|##########| 906/906 [01:30<00:00, 10.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:00:00,489 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6245, MEAN__relation_recall: 0.4725, MEAN__relation_f1: 0.5380, batch_loss: 2.0428, loss: 10.8944 ||: 100%|##########| 219/219 [00:05<00:00, 37.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:00:06,360 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:00:06,362 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.567  |     0.538\n",
            "2022-11-30 10:00:06,367 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.614  |     0.625\n",
            "2022-11-30 10:00:06,370 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.527  |     0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:00:06,373 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.859  |     0.785\n",
            "2022-11-30 10:00:06,377 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.878  |     0.807\n",
            "2022-11-30 10:00:06,381 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.841  |     0.765\n",
            "2022-11-30 10:00:06,385 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.859  |     0.785\n",
            "2022-11-30 10:00:06,387 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.878  |     0.807\n",
            "2022-11-30 10:00:06,389 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.841  |     0.765\n",
            "2022-11-30 10:00:06,394 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.567  |     0.538\n",
            "2022-11-30 10:00:06,397 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.614  |     0.625\n",
            "2022-11-30 10:00:06,401 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.527  |     0.472\n",
            "2022-11-30 10:00:06,405 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:00:06,409 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.387  |    10.894\n",
            "2022-11-30 10:00:06,413 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n",
            "2022-11-30 10:00:09,007 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 10:00:11,457 - INFO - allennlp.training.trainer - Epoch duration: 0:01:42.639040\n",
            "2022-11-30 10:00:11,460 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:29\n",
            "2022-11-30 10:00:11,462 - INFO - allennlp.training.trainer - Epoch 3/9\n",
            "2022-11-30 10:00:11,466 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:00:11,468 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:00:11,476 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6830, MEAN__relation_recall: 0.6288, MEAN__relation_f1: 0.6548, batch_loss: 23.9830, loss: 5.8801 ||: 100%|##########| 906/906 [01:32<00:00,  9.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:01:44,796 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6699, MEAN__relation_recall: 0.4000, MEAN__relation_f1: 0.5009, batch_loss: 73.8215, loss: 13.8419 ||: 100%|##########| 219/219 [00:05<00:00, 37.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:01:50,648 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:01:50,650 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.655  |     0.501\n",
            "2022-11-30 10:01:50,653 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.683  |     0.670\n",
            "2022-11-30 10:01:50,658 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.629  |     0.400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:01:50,662 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.909  |     0.784\n",
            "2022-11-30 10:01:50,667 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.921  |     0.781\n",
            "2022-11-30 10:01:50,669 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.896  |     0.788\n",
            "2022-11-30 10:01:50,672 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.909  |     0.784\n",
            "2022-11-30 10:01:50,675 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.921  |     0.781\n",
            "2022-11-30 10:01:50,679 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.896  |     0.788\n",
            "2022-11-30 10:01:50,682 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.655  |     0.501\n",
            "2022-11-30 10:01:50,684 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.683  |     0.670\n",
            "2022-11-30 10:01:50,688 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.629  |     0.400\n",
            "2022-11-30 10:01:50,693 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:01:50,697 - INFO - allennlp.training.tensorboard_writer - loss                      |     5.880  |    13.842\n",
            "2022-11-30 10:01:50,701 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n",
            "2022-11-30 10:01:53,198 - INFO - allennlp.training.trainer - Epoch duration: 0:01:41.736148\n",
            "2022-11-30 10:01:53,199 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:55\n",
            "2022-11-30 10:01:53,201 - INFO - allennlp.training.trainer - Epoch 4/9\n",
            "2022-11-30 10:01:53,207 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:01:53,210 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:01:53,212 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.7538, MEAN__relation_recall: 0.7151, MEAN__relation_f1: 0.7339, batch_loss: 0.0678, loss: 4.1555 ||: 100%|##########| 906/906 [01:31<00:00,  9.90it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:03:25,856 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.5850, MEAN__relation_recall: 0.4986, MEAN__relation_f1: 0.5383, batch_loss: 2.1728, loss: 15.2256 ||: 100%|##########| 219/219 [00:05<00:00, 37.51it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:03:31,702 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:03:31,705 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.734  |     0.538\n",
            "2022-11-30 10:03:31,709 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.754  |     0.585\n",
            "2022-11-30 10:03:31,712 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.715  |     0.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:03:31,714 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.948  |     0.787\n",
            "2022-11-30 10:03:31,718 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.952  |     0.789\n",
            "2022-11-30 10:03:31,722 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.943  |     0.785\n",
            "2022-11-30 10:03:31,725 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.948  |     0.787\n",
            "2022-11-30 10:03:31,728 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.952  |     0.789\n",
            "2022-11-30 10:03:31,732 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.943  |     0.785\n",
            "2022-11-30 10:03:31,735 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.734  |     0.538\n",
            "2022-11-30 10:03:31,737 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.754  |     0.585\n",
            "2022-11-30 10:03:31,740 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.715  |     0.499\n",
            "2022-11-30 10:03:31,742 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:03:31,751 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.156  |    15.226\n",
            "2022-11-30 10:03:31,754 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n",
            "2022-11-30 10:03:34,213 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 10:03:36,479 - INFO - allennlp.training.trainer - Epoch duration: 0:01:43.277794\n",
            "2022-11-30 10:03:36,481 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:08:20\n",
            "2022-11-30 10:03:36,482 - INFO - allennlp.training.trainer - Epoch 5/9\n",
            "2022-11-30 10:03:36,487 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:03:36,489 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:03:36,494 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.8088, MEAN__relation_recall: 0.7678, MEAN__relation_f1: 0.7878, batch_loss: 9.5802, loss: 3.4306 ||: 100%|##########| 906/906 [01:31<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:05:09,071 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6602, MEAN__relation_recall: 0.4957, MEAN__relation_f1: 0.5662, batch_loss: 8.7404, loss: 14.9864 ||: 100%|##########| 219/219 [00:05<00:00, 39.15it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:05:14,674 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:05:14,675 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.788  |     0.566\n",
            "2022-11-30 10:05:14,679 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.809  |     0.660\n",
            "2022-11-30 10:05:14,683 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.768  |     0.496\n",
            "2022-11-30 10:05:14,687 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.959  |     0.797\n",
            "2022-11-30 10:05:14,690 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.968  |     0.765\n",
            "2022-11-30 10:05:14,696 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.951  |     0.833\n",
            "2022-11-30 10:05:14,699 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.959  |     0.797\n",
            "2022-11-30 10:05:14,702 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.968  |     0.765\n",
            "2022-11-30 10:05:14,705 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.951  |     0.833\n",
            "2022-11-30 10:05:14,709 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.788  |     0.566\n",
            "2022-11-30 10:05:14,712 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.809  |     0.660\n",
            "2022-11-30 10:05:14,715 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.768  |     0.496\n",
            "2022-11-30 10:05:14,718 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:05:14,721 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.431  |    14.986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:05:14,724 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n",
            "2022-11-30 10:05:16,917 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 10:05:19,370 - INFO - allennlp.training.trainer - Epoch duration: 0:01:42.888229\n",
            "2022-11-30 10:05:19,373 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:42\n",
            "2022-11-30 10:05:19,376 - INFO - allennlp.training.trainer - Epoch 6/9\n",
            "2022-11-30 10:05:19,378 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:05:19,382 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:05:19,384 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.8555, MEAN__relation_recall: 0.8151, MEAN__relation_f1: 0.8348, batch_loss: 1.4247, loss: 2.5191 ||: 100%|##########| 906/906 [01:23<00:00, 10.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:06:43,968 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.5983, MEAN__relation_recall: 0.6000, MEAN__relation_f1: 0.5991, batch_loss: 0.0000, loss: 22.8401 ||: 100%|##########| 219/219 [00:04<00:00, 44.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:06:48,877 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:06:48,879 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.835  |     0.599\n",
            "2022-11-30 10:06:48,882 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.855  |     0.598\n",
            "2022-11-30 10:06:48,885 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.815  |     0.600\n",
            "2022-11-30 10:06:48,888 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.974  |     0.813\n",
            "2022-11-30 10:06:48,890 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.978  |     0.802\n",
            "2022-11-30 10:06:48,895 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.971  |     0.825\n",
            "2022-11-30 10:06:48,897 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.974  |     0.813\n",
            "2022-11-30 10:06:48,902 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.978  |     0.802\n",
            "2022-11-30 10:06:48,904 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.971  |     0.825\n",
            "2022-11-30 10:06:48,906 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.835  |     0.599\n",
            "2022-11-30 10:06:48,911 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.855  |     0.598\n",
            "2022-11-30 10:06:48,913 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.815  |     0.600\n",
            "2022-11-30 10:06:48,916 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:06:48,918 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.519  |    22.840\n",
            "2022-11-30 10:06:48,927 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:06:51,250 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 10:06:53,622 - INFO - allennlp.training.trainer - Epoch duration: 0:01:34.246303\n",
            "2022-11-30 10:06:53,623 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:58\n",
            "2022-11-30 10:06:53,627 - INFO - allennlp.training.trainer - Epoch 7/9\n",
            "2022-11-30 10:06:53,628 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:06:53,631 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:06:53,634 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.8865, MEAN__relation_recall: 0.8610, MEAN__relation_f1: 0.8735, batch_loss: 3.1548, loss: 1.9520 ||: 100%|##########| 906/906 [01:22<00:00, 10.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:08:17,420 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6149, MEAN__relation_recall: 0.5739, MEAN__relation_f1: 0.5937, batch_loss: 0.0000, loss: 19.9435 ||: 100%|##########| 219/219 [00:04<00:00, 44.14it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:08:22,388 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:08:22,391 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.874  |     0.594\n",
            "2022-11-30 10:08:22,394 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.886  |     0.615\n",
            "2022-11-30 10:08:22,399 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.861  |     0.574\n",
            "2022-11-30 10:08:22,402 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.981  |     0.790\n",
            "2022-11-30 10:08:22,404 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.985  |     0.737\n",
            "2022-11-30 10:08:22,407 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.977  |     0.852\n",
            "2022-11-30 10:08:22,410 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.981  |     0.790\n",
            "2022-11-30 10:08:22,412 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.985  |     0.737\n",
            "2022-11-30 10:08:22,416 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.977  |     0.852\n",
            "2022-11-30 10:08:22,419 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.874  |     0.594\n",
            "2022-11-30 10:08:22,423 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.886  |     0.615\n",
            "2022-11-30 10:08:22,425 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.861  |     0.574\n",
            "2022-11-30 10:08:22,428 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:08:22,431 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.952  |    19.943\n",
            "2022-11-30 10:08:22,442 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:08:24,820 - INFO - allennlp.training.trainer - Epoch duration: 0:01:31.193146\n",
            "2022-11-30 10:08:24,822 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:17\n",
            "2022-11-30 10:08:24,824 - INFO - allennlp.training.trainer - Epoch 8/9\n",
            "2022-11-30 10:08:24,830 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:08:24,831 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:08:24,837 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.9113, MEAN__relation_recall: 0.9144, MEAN__relation_f1: 0.9128, batch_loss: 0.1711, loss: 1.2545 ||: 100%|##########| 906/906 [01:23<00:00, 10.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:09:49,356 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6380, MEAN__relation_recall: 0.6029, MEAN__relation_f1: 0.6200, batch_loss: 0.0000, loss: 23.5739 ||: 100%|##########| 219/219 [00:05<00:00, 38.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:09:55,058 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:09:55,062 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.913  |     0.620\n",
            "2022-11-30 10:09:55,065 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.911  |     0.638\n",
            "2022-11-30 10:09:55,068 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.914  |     0.603\n",
            "2022-11-30 10:09:55,073 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.988  |     0.803\n",
            "2022-11-30 10:09:55,076 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.988  |     0.779\n",
            "2022-11-30 10:09:55,081 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.988  |     0.828\n",
            "2022-11-30 10:09:55,084 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.988  |     0.803\n",
            "2022-11-30 10:09:55,086 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.988  |     0.779\n",
            "2022-11-30 10:09:55,089 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.988  |     0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:09:55,092 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.913  |     0.620\n",
            "2022-11-30 10:09:55,099 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.911  |     0.638\n",
            "2022-11-30 10:09:55,101 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.914  |     0.603\n",
            "2022-11-30 10:09:55,105 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:09:55,107 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.255  |    23.574\n",
            "2022-11-30 10:09:55,114 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n",
            "2022-11-30 10:09:57,447 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 10:09:59,824 - INFO - allennlp.training.trainer - Epoch duration: 0:01:35.000283\n",
            "2022-11-30 10:09:59,826 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:38\n",
            "2022-11-30 10:09:59,827 - INFO - allennlp.training.trainer - Epoch 9/9\n",
            "2022-11-30 10:09:59,832 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 10:09:59,835 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 10:09:59,842 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.9365, MEAN__relation_recall: 0.9390, MEAN__relation_f1: 0.9378, batch_loss: 2.2703, loss: 0.7765 ||: 100%|##########| 906/906 [01:30<00:00, 10.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:11:31,590 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6322, MEAN__relation_recall: 0.6029, MEAN__relation_f1: 0.6172, batch_loss: 0.0000, loss: 26.3488 ||: 100%|##########| 219/219 [00:06<00:00, 36.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:11:37,633 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 10:11:37,636 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.938  |     0.617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:11:37,639 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.936  |     0.632\n",
            "2022-11-30 10:11:37,643 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.939  |     0.603\n",
            "2022-11-30 10:11:37,646 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.993  |     0.800\n",
            "2022-11-30 10:11:37,648 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.994  |     0.764\n",
            "2022-11-30 10:11:37,651 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.993  |     0.838\n",
            "2022-11-30 10:11:37,657 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.993  |     0.800\n",
            "2022-11-30 10:11:37,659 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.994  |     0.764\n",
            "2022-11-30 10:11:37,664 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.993  |     0.838\n",
            "2022-11-30 10:11:37,667 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.938  |     0.617\n",
            "2022-11-30 10:11:37,670 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.936  |     0.632\n",
            "2022-11-30 10:11:37,674 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.939  |     0.603\n",
            "2022-11-30 10:11:37,680 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 10:11:37,683 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.776  |    26.349\n",
            "2022-11-30 10:11:37,687 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4143.617  |       N/A\n",
            "2022-11-30 10:11:40,226 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.398822\n",
            "2022-11-30 10:11:40,227 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2022-11-30 10:11:40,585 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
            "2022-11-30 10:11:40,588 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"best_epoch\": 8,\n",
            "  \"peak_worker_0_memory_MB\": 4143.6171875,\n",
            "  \"peak_gpu_0_memory_MB\": 1871.78857421875,\n",
            "  \"training_duration\": \"0:16:21.551536\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 9,\n",
            "  \"epoch\": 9,\n",
            "  \"training__None__ner_precision\": 0.9937156323644933,\n",
            "  \"training__None__ner_recall\": 0.9929356357927787,\n",
            "  \"training__None__ner_f1\": 0.9933254809579898,\n",
            "  \"training__MEAN__ner_precision\": 0.9937156323644933,\n",
            "  \"training__MEAN__ner_recall\": 0.9929356357927787,\n",
            "  \"training__MEAN__ner_f1\": 0.9933254809579898,\n",
            "  \"training__None__relation_precision\": 0.9364754098360656,\n",
            "  \"training__None__relation_recall\": 0.939041095890411,\n",
            "  \"training__None__relation_f1\": 0.9377564979480165,\n",
            "  \"training_MEAN__relation_precision\": 0.9364754098360656,\n",
            "  \"training_MEAN__relation_recall\": 0.939041095890411,\n",
            "  \"training_MEAN__relation_f1\": 0.9377564979480165,\n",
            "  \"training_loss\": 0.7764622928565804,\n",
            "  \"training_worker_0_memory_MB\": 4143.6171875,\n",
            "  \"training_gpu_0_memory_MB\": 1871.78857421875,\n",
            "  \"validation__None__ner_precision\": 0.7644376899696048,\n",
            "  \"validation__None__ner_recall\": 0.8383333333333334,\n",
            "  \"validation__None__ner_f1\": 0.7996820349761525,\n",
            "  \"validation__MEAN__ner_precision\": 0.7644376899696048,\n",
            "  \"validation__MEAN__ner_recall\": 0.8383333333333334,\n",
            "  \"validation__MEAN__ner_f1\": 0.7996820349761525,\n",
            "  \"validation__None__relation_precision\": 0.6322188449848024,\n",
            "  \"validation__None__relation_recall\": 0.6028985507246377,\n",
            "  \"validation__None__relation_f1\": 0.6172106824925816,\n",
            "  \"validation_MEAN__relation_precision\": 0.6322188449848024,\n",
            "  \"validation_MEAN__relation_recall\": 0.6028985507246377,\n",
            "  \"validation_MEAN__relation_f1\": 0.6172106824925816,\n",
            "  \"validation_loss\": 26.348849522740682,\n",
            "  \"best_validation__None__ner_precision\": 0.7789968652037618,\n",
            "  \"best_validation__None__ner_recall\": 0.8283333333333334,\n",
            "  \"best_validation__None__ner_f1\": 0.802907915993538,\n",
            "  \"best_validation__MEAN__ner_precision\": 0.7789968652037618,\n",
            "  \"best_validation__MEAN__ner_recall\": 0.8283333333333334,\n",
            "  \"best_validation__MEAN__ner_f1\": 0.802907915993538,\n",
            "  \"best_validation__None__relation_precision\": 0.6380368098159509,\n",
            "  \"best_validation__None__relation_recall\": 0.6028985507246377,\n",
            "  \"best_validation__None__relation_f1\": 0.6199701937406856,\n",
            "  \"best_validation_MEAN__relation_precision\": 0.6380368098159509,\n",
            "  \"best_validation_MEAN__relation_recall\": 0.6028985507246377,\n",
            "  \"best_validation_MEAN__relation_f1\": 0.6199701937406856,\n",
            "  \"best_validation_loss\": 23.573900690037362\n",
            "}\n",
            "2022-11-30 10:11:40,594 - INFO - allennlp.models.archival - archiving weights and vocabulary to outputs/14lap/seed_4/weights/model.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate SpanModel F1 Score\n",
        "import json\n",
        "\n",
        "path_pred = \"pred.txt\"\n",
        "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
        "model.predict(path_in=path_test, path_out=path_pred)\n",
        "results = model.score(path_pred, path_test)\n",
        "print(json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "VILDnY_396m1",
        "outputId": "3ce76c1b-cbae-453b-a04b-37c2cb9141d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 10:14:38,582 - INFO - allennlp.models.archival - loading archive file outputs/14lap/seed_4/weights/model.tar.gz\n",
            "2022-11-30 10:14:38,587 - INFO - allennlp.models.archival - extracting archive file outputs/14lap/seed_4/weights/model.tar.gz to temp dir /tmp/tmp8xhacjex\n",
            "2022-11-30 10:14:42,697 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
            "2022-11-30 10:14:42,699 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-11-30 10:14:42,700 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-11-30 10:14:42,704 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-11-30 10:14:42,706 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-11-30 10:14:42,709 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-11-30 10:14:42,711 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
            "2022-11-30 10:14:42,713 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 10:14:42,715 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
            "2022-11-30 10:14:42,718 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
            "2022-11-30 10:14:42,720 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
            "2022-11-30 10:14:42,722 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
            "2022-11-30 10:14:42,725 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
            "################################################################################\n",
            "2022-11-30 10:14:42,727 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
            "2022-11-30 10:14:42,729 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-11-30 10:14:42,731 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-11-30 10:14:42,733 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-11-30 10:14:42,735 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-11-30 10:14:42,741 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-11-30 10:14:42,743 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
            "2022-11-30 10:14:42,747 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 10:14:42,748 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
            "2022-11-30 10:14:42,750 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
            "2022-11-30 10:14:42,751 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
            "2022-11-30 10:14:42,753 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
            "2022-11-30 10:14:42,756 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
            "################################################################################\n",
            "2022-11-30 10:14:42,758 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-11-30 10:14:42,761 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp8xhacjex/vocabulary.\n",
            "2022-11-30 10:14:42,767 - INFO - filelock - Lock 139692470601360 acquired on /tmp/tmp8xhacjex/vocabulary/.lock\n",
            "2022-11-30 10:14:42,769 - INFO - filelock - Lock 139692470601360 released on /tmp/tmp8xhacjex/vocabulary/.lock\n",
            "2022-11-30 10:14:42,771 - INFO - allennlp.common.params - model.type = span_model\n",
            "2022-11-30 10:14:42,773 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-11-30 10:14:42,775 - INFO - allennlp.common.params - model.embedder.type = basic\n",
            "2022-11-30 10:14:42,777 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 10:14:42,779 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
            "2022-11-30 10:14:42,781 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
            "2022-11-30 10:14:42,782 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
            "2022-11-30 10:14:42,785 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
            "2022-11-30 10:14:42,789 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
            "2022-11-30 10:14:42,790 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
            "2022-11-30 10:14:42,792 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
            "2022-11-30 10:14:42,887 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
            "2022-11-30 10:14:42,889 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
            "2022-11-30 10:14:42,890 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
            "2022-11-30 10:14:42,895 - INFO - allennlp.common.params - model.feature_size = 20\n",
            "2022-11-30 10:14:42,896 - INFO - allennlp.common.params - model.max_span_width = 8\n",
            "2022-11-30 10:14:42,897 - INFO - allennlp.common.params - model.target_task = relation\n",
            "2022-11-30 10:14:42,902 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f0d49815290>\n",
            "2022-11-30 10:14:42,905 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
            "2022-11-30 10:14:42,906 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
            "2022-11-30 10:14:42,910 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
            "2022-11-30 10:14:42,913 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
            "2022-11-30 10:14:42,915 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
            "2022-11-30 10:14:42,919 - INFO - allennlp.common.params - model.display_metrics = None\n",
            "2022-11-30 10:14:42,922 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
            "2022-11-30 10:14:42,924 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "2022-11-30 10:14:42,928 - INFO - allennlp.common.params - ner.regularizer = None\n",
            "2022-11-30 10:14:42,929 - INFO - allennlp.common.params - ner.name = ner_labels\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "2022-11-30 10:14:42,938 - INFO - allennlp.common.params - relation.regularizer = None\n",
            "2022-11-30 10:14:42,940 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
            "2022-11-30 10:14:42,943 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
            "2022-11-30 10:14:42,944 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
            "2022-11-30 10:14:42,946 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
            "2022-11-30 10:14:42,948 - INFO - allennlp.common.params - relation.use_pruning = True\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f0cb2997560>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__relation_labels, Size: 3 || None__ner_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "2022-11-30 10:14:42,967 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 10:14:42,970 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
            "2022-11-30 10:14:42,974 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
            "2022-11-30 10:14:42,977 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
            "2022-11-30 10:14:42,979 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-11-30 10:14:42,980 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 10:14:42,982 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 10:14:42,986 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 10:14:42,987 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 10:14:42,989 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 10:14:42,991 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
            "2022-11-30 10:14:42,995 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
            "2022-11-30 10:14:43,004 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
            "2022-11-30 10:14:43,007 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
            "2022-11-30 10:14:43,009 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-11-30 10:14:43,011 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 10:14:43,013 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 10:14:43,016 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 10:14:43,021 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 10:14:43,022 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 10:14:43,028 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 10:14:43,029 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-11-30 10:14:43,032 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-11-30 10:14:43,034 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-11-30 10:14:43,035 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-11-30 10:14:43,038 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-11-30 10:14:43,039 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,043 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,044 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,046 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,048 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-11-30 10:14:43,050 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-11-30 10:14:43,051 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-11-30 10:14:43,053 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-11-30 10:14:43,057 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-11-30 10:14:43,059 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-11-30 10:14:43,062 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,065 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,070 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-11-30 10:14:43,075 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-11-30 10:14:43,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,079 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-11-30 10:14:43,088 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-11-30 10:14:43,093 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-11-30 10:14:43,093 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-11-30 10:14:43,095 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-11-30 10:14:43,097 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-11-30 10:14:43,101 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,104 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,106 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,111 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,114 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-11-30 10:14:43,116 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-11-30 10:14:43,118 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,119 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,123 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,125 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,126 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-11-30 10:14:43,128 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-11-30 10:14:43,131 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-11-30 10:14:43,132 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-11-30 10:14:43,134 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-11-30 10:14:43,138 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-11-30 10:14:43,139 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,143 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,144 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,148 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,150 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-11-30 10:14:43,151 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-11-30 10:14:43,154 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,155 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,157 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,159 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,160 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-11-30 10:14:43,162 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-11-30 10:14:43,166 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-11-30 10:14:43,171 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-11-30 10:14:43,173 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-11-30 10:14:43,174 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-11-30 10:14:43,178 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,181 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,184 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,185 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,188 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-11-30 10:14:43,190 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-11-30 10:14:43,191 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,193 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,195 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,198 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,200 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-11-30 10:14:43,201 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-11-30 10:14:43,203 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-11-30 10:14:43,204 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-11-30 10:14:43,208 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-11-30 10:14:43,209 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-11-30 10:14:43,210 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,211 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,215 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,217 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,220 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-11-30 10:14:43,221 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-11-30 10:14:43,223 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,227 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,228 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,230 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,233 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-11-30 10:14:43,237 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-11-30 10:14:43,238 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-11-30 10:14:43,241 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-11-30 10:14:43,245 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-11-30 10:14:43,247 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-11-30 10:14:43,248 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,250 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,253 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,255 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,256 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-11-30 10:14:43,257 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-11-30 10:14:43,258 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,262 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,264 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,266 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,267 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-11-30 10:14:43,269 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-11-30 10:14:43,274 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-11-30 10:14:43,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-11-30 10:14:43,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-11-30 10:14:43,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-11-30 10:14:43,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,289 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,292 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-11-30 10:14:43,294 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-11-30 10:14:43,298 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,300 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,302 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,304 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-11-30 10:14:43,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-11-30 10:14:43,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-11-30 10:14:43,313 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-11-30 10:14:43,316 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-11-30 10:14:43,317 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-11-30 10:14:43,319 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,321 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,325 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,328 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,331 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-11-30 10:14:43,332 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-11-30 10:14:43,337 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,339 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,341 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,342 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,347 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-11-30 10:14:43,349 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-11-30 10:14:43,351 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-11-30 10:14:43,354 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-11-30 10:14:43,356 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-11-30 10:14:43,359 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-11-30 10:14:43,363 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,364 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,368 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,369 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,372 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-11-30 10:14:43,375 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-11-30 10:14:43,377 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,379 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,381 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,386 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,387 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-11-30 10:14:43,391 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-11-30 10:14:43,393 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-11-30 10:14:43,395 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-11-30 10:14:43,397 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-11-30 10:14:43,398 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-11-30 10:14:43,401 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,402 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,405 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,407 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,410 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-11-30 10:14:43,411 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-11-30 10:14:43,414 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,415 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,418 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,419 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,421 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-11-30 10:14:43,423 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-11-30 10:14:43,425 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-11-30 10:14:43,427 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-11-30 10:14:43,428 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-11-30 10:14:43,430 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-11-30 10:14:43,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,434 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,438 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-11-30 10:14:43,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-11-30 10:14:43,448 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,450 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,454 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-11-30 10:14:43,457 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-11-30 10:14:43,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-11-30 10:14:43,464 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-11-30 10:14:43,466 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-11-30 10:14:43,469 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-11-30 10:14:43,470 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-11-30 10:14:43,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-11-30 10:14:43,475 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-11-30 10:14:43,477 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-11-30 10:14:43,479 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-11-30 10:14:43,482 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-11-30 10:14:43,484 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-11-30 10:14:43,486 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-11-30 10:14:43,488 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-11-30 10:14:43,490 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-11-30 10:14:43,492 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
            "2022-11-30 10:14:43,497 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 10:14:43,499 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-11-30 10:14:43,501 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 10:14:43,505 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-11-30 10:14:43,508 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 10:14:43,510 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-11-30 10:14:43,513 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 10:14:43,515 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-11-30 10:14:43,518 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 10:14:43,520 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-11-30 10:14:43,522 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 10:14:43,524 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-11-30 10:14:43,526 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
            "2022-11-30 10:14:43,682 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
            "2022-11-30 10:14:43,956 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp8xhacjex\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 328it [00:00, 1500.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"path_pred\": \"pred.txt\",\n",
            "  \"path_gold\": \"aste/data/triplet_data/14lap/test.txt\",\n",
            "  \"precision\": 0.6338912133891214,\n",
            "  \"recall\": 0.5580110497237569,\n",
            "  \"score\": 0.5935357492654261\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}